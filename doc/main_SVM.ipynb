{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import sklearn.metrics\n",
    "import sklearn \n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: set work directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../data/train_set/'\n",
    "image_dir = train_dir+\"images/\"\n",
    "pt_dir = train_dir+\"points/\"\n",
    "label_path = train_dir+\"label.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide directories for training images. \n",
    "Training images and Training fiducial points will be in different subfolders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: set up controls for evaluation experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chunk, we have a set of controls for the evaluation experiments.\n",
    "\n",
    "• (T/F) initial feature extraction on training set\n",
    "• (T/F) initial feature extraction on test set\n",
    "• (T/F) improved feature extraction on training set\n",
    "• (T/F) improved feature extraction on test set\n",
    "• (T/F) SMOTE using improved features on train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_feature_train_initial = True\n",
    "run_feature_test_initial = True\n",
    "\n",
    "run_feature_train = True # process features for training set\n",
    "run_feature_test = True # process features for test set\n",
    "\n",
    "run_feature_train_SMOTE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chunk,we have a set of controls for model training/testing. \n",
    "If true, then we train the model and generate predictions on the test set, and if false, then we skip that model. \n",
    "By default all the models are set to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_baseline = True\n",
    "run_advanced = True\n",
    "\n",
    "run_baseline_improved = True\n",
    "run_knn = True\n",
    "run_random_forest=True\n",
    "run_svm = True\n",
    "run_weighted_svm = True\n",
    "run_stochastic_gradient_descent = True\n",
    "run_neural_networks = True\n",
    "run_decision_tree = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fold cross validation with AUC scoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cv = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2:  import data and train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiducial points are stored in matlab format. In this step, we read them and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(train_dir):\n",
    "  \n",
    "  # read labels\n",
    "  labels = pd.read_csv(train_dir+'/label.csv')\n",
    "  y= labels['label'].to_numpy()\n",
    "\n",
    "  # read points\n",
    "  n = 3000\n",
    "  for i in range(1,n+1):\n",
    "    p_path = str(i).zfill(4)+'.mat'\n",
    "    mat = scipy.io.loadmat(train_dir+'/points/'+p_path)\n",
    "    if 'faceCoordinatesUnwarped' in mat:\n",
    "      cords = mat['faceCoordinatesUnwarped'] \n",
    "    else:\n",
    "      cords = mat['faceCoordinates2']\n",
    "\n",
    "    distance = sklearn.metrics.pairwise_distances(cords)       \n",
    "          # compute the pairwise distances in each mat\n",
    "    flatten_distance = distance[np.triu_indices(len(cords[:,0]), k = 1)]    \n",
    "          # stretch the upper triangle of the symmetric matrix \n",
    "          # to a long array with dimension 3003\n",
    "          # 3003 = (1+77)*78/2\n",
    "    if i==1:\n",
    "      distances = np.mat([flatten_distance])\n",
    "    else:\n",
    "      distances = np.append(distances, np.mat([flatten_distance]), axis = 0)\n",
    "  return (distances, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_time_start=time.time()\n",
    "X, Y = read_data(train_dir)\n",
    "print(\"Read the original dataset takes %s seconds\" % round((time.time() - read_time_start),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing Imbalanced Dataset (SMOTE)-oversamplig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class: 2402\n",
      "minority class: 598\n"
     ]
    }
   ],
   "source": [
    "print('majority class: %d' % np.sum(Y == 0))\n",
    "print('minority class: %d' % np.sum(Y == 1))\n",
    "#imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(X, Y, train_dir):\n",
    "\n",
    "  distances = X\n",
    "  y = Y\n",
    "\n",
    "  n = y.shape[0]\n",
    "  mat_1 = np.add(np.where(y == 1),1)\n",
    "  n_oversample = (n-sum(y))-sum(y) \n",
    "    # how many samples do we need to generate\n",
    "\n",
    "  for i in range(n_oversample):\n",
    "    samples_index = random.sample(list(list(mat_1)[0]), 2)\n",
    "      # pick two random index of class 1 samples. \n",
    "\n",
    "    p_path = str(samples_index[0]).zfill(4)+'.mat'\n",
    "    mat = scipy.io.loadmat(train_dir+'/points/'+p_path)\n",
    "    if 'faceCoordinatesUnwarped' in mat:\n",
    "      cords_0 = mat['faceCoordinatesUnwarped'] \n",
    "    else:\n",
    "      cords_0 = mat['faceCoordinates2']\n",
    "    \n",
    "    p_path = str(samples_index[1]).zfill(4)+'.mat'\n",
    "    mat = scipy.io.loadmat(train_dir+'/points/'+p_path)\n",
    "    if 'faceCoordinatesUnwarped' in mat:\n",
    "      cords_1 = mat['faceCoordinatesUnwarped'] \n",
    "    else:\n",
    "      cords_1 = mat['faceCoordinates2']\n",
    "\n",
    "    cords_new = (cords_0 + cords_1) / 2 \n",
    "        # averaging two sets of cordinates to generate new set of cordinates\n",
    "    distance = sklearn.metrics.pairwise_distances(cords_new)\n",
    "        # compute the pairwise distances in each mat\n",
    "    flatten_distance = distance[np.triu_indices(len(cords_new[:,0]), k = 1)]\n",
    "        # stretch the upper triangle of the symmetric matrix \n",
    "        # to a long array with dimension 3003\n",
    "        # 3003 = (1+77)*78/2\n",
    "    \n",
    "    distances = np.append(distances, np.mat([flatten_distance]), axis = 0)\n",
    "    y = np.append(y,np.array(1))\n",
    "        # Append new data to the original dataset\n",
    "\n",
    "  return (distances, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balanced_X, Blanced_Y = data_preprocessing(X, Y, train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4804, 3003), (4804,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Balanced_X.shape, Blanced_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train-test split\n",
    "since we can see that the dataset is imbalanced, in this chunk we do an 80-20 train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import smote_variants as sv\n",
    "import imbalanced_databases as imbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test with 80-20\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(Balanced_X, Blanced_Y,test_size=0.2,random_state=0)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: construct features and responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBM model goes here (both original and updated)\n",
    "\n",
    "• The follow plots show how pairwise distance between fiducial points can work as feature for facial emotion recognition.\n",
    "\n",
    "    – In the first column, 78 fiducials points of each emotion are marked in order.\n",
    "    – In the second column distributions of vertical distance between right pupil(1) and right brow peak(21) are shown in histograms. For example, the distance of an angry face tends to be shorter than that of a surprised face.\n",
    "    – The third column is the distributions of vertical distances between right mouth corner(50) and the midpoint of the upper lip(52). For example, the distance of an happy face tends to be shorter than that of a sad face.\n",
    "\n",
    "this is step is to identify and improve features \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Step 4: GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best gbm model\n",
    "pickle.dump(gbm_best, open(\"../output/baseline_gbm.p\",'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save trained weighted SVM model\n",
    "pickle.dump(weighted_svm_best, open(\"../output/baseline_gbm.p\",'wb','wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Train a classification model with training features and responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply advanced model to fit the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Run test on test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run trained model with test data and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV,RepeatedStratifiedKFold,cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import scipy.io\n",
    "import pickle\n",
    "import os, sys\n",
    "from scipy.spatial.distance import pdist\n",
    "import time \n",
    "import xlsxwriter\n",
    "from sklearn.metrics import accuracy_score, classification_report,make_scorer, confusion_matrix,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END .....................C=0.1, gamma=1, kernel=rbf; total time=  28.5s\n",
      "[CV 2/5] END .....................C=0.1, gamma=1, kernel=rbf; total time=  24.6s\n",
      "[CV 3/5] END .....................C=0.1, gamma=1, kernel=rbf; total time=  26.3s\n",
      "[CV 4/5] END .....................C=0.1, gamma=1, kernel=rbf; total time=  25.7s\n",
      "[CV 5/5] END .....................C=0.1, gamma=1, kernel=rbf; total time=  27.2s\n",
      "[CV 1/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  26.8s\n",
      "[CV 2/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  27.4s\n",
      "[CV 3/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  26.9s\n",
      "[CV 4/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  26.2s\n",
      "[CV 5/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  26.3s\n",
      "[CV 1/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=  27.4s\n",
      "[CV 2/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=  25.7s\n",
      "[CV 3/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=  25.4s\n",
      "[CV 4/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=  24.8s\n",
      "[CV 5/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=  25.3s\n",
      "[CV 1/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=  24.2s\n",
      "[CV 2/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=  24.0s\n",
      "[CV 3/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=  24.2s\n",
      "[CV 4/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=  24.6s\n",
      "[CV 5/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=  24.3s\n",
      "[CV 1/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=  23.3s\n",
      "[CV 2/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=  23.5s\n",
      "[CV 3/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=  23.5s\n",
      "[CV 4/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=  23.3s\n",
      "[CV 5/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=  23.4s\n",
      "[CV 1/5] END .......................C=1, gamma=1, kernel=rbf; total time=  27.0s\n",
      "[CV 2/5] END .......................C=1, gamma=1, kernel=rbf; total time=  28.0s\n",
      "[CV 3/5] END .......................C=1, gamma=1, kernel=rbf; total time=  25.3s\n",
      "[CV 4/5] END .......................C=1, gamma=1, kernel=rbf; total time=  28.2s\n",
      "[CV 5/5] END .......................C=1, gamma=1, kernel=rbf; total time=  26.5s\n",
      "[CV 1/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=  27.1s\n",
      "[CV 2/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=  29.7s\n",
      "[CV 3/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=  26.1s\n",
      "[CV 4/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=  27.3s\n",
      "[CV 5/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=  30.5s\n",
      "[CV 1/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  29.1s\n",
      "[CV 2/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  29.1s\n",
      "[CV 3/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  29.1s\n",
      "[CV 4/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  29.1s\n",
      "[CV 5/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  28.7s\n",
      "[CV 1/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  27.3s\n",
      "[CV 2/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  26.9s\n",
      "[CV 3/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  24.7s\n",
      "[CV 4/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  24.8s\n",
      "[CV 5/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  25.1s\n",
      "[CV 1/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=  23.8s\n",
      "[CV 2/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=  23.3s\n",
      "[CV 3/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=  25.3s\n",
      "[CV 4/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=  23.3s\n",
      "[CV 5/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=  23.5s\n",
      "[CV 1/5] END ......................C=10, gamma=1, kernel=rbf; total time=  24.0s\n",
      "[CV 2/5] END ......................C=10, gamma=1, kernel=rbf; total time=  24.2s\n",
      "[CV 3/5] END ......................C=10, gamma=1, kernel=rbf; total time=  25.2s\n",
      "[CV 4/5] END ......................C=10, gamma=1, kernel=rbf; total time=  24.2s\n",
      "[CV 5/5] END ......................C=10, gamma=1, kernel=rbf; total time=  24.6s\n",
      "[CV 1/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=  24.4s\n",
      "[CV 2/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=  23.5s\n",
      "[CV 3/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=  23.7s\n",
      "[CV 4/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=  24.2s\n",
      "[CV 5/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=  24.3s\n",
      "[CV 1/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  24.1s\n",
      "[CV 2/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  23.7s\n",
      "[CV 3/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  24.0s\n",
      "[CV 4/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  23.6s\n",
      "[CV 5/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  24.8s\n",
      "[CV 1/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  24.6s\n",
      "[CV 2/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  24.0s\n",
      "[CV 3/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  24.6s\n",
      "[CV 4/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  24.5s\n",
      "[CV 5/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  23.8s\n",
      "[CV 1/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=  23.8s\n",
      "[CV 2/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=  24.7s\n",
      "[CV 3/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=  23.6s\n",
      "[CV 4/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=  23.2s\n",
      "[CV 5/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=  24.3s\n",
      "[CV 1/5] END .....................C=100, gamma=1, kernel=rbf; total time=  24.2s\n",
      "[CV 2/5] END .....................C=100, gamma=1, kernel=rbf; total time=  24.3s\n",
      "[CV 3/5] END .....................C=100, gamma=1, kernel=rbf; total time=  24.9s\n",
      "[CV 4/5] END .....................C=100, gamma=1, kernel=rbf; total time=  23.8s\n",
      "[CV 5/5] END .....................C=100, gamma=1, kernel=rbf; total time=  23.7s\n",
      "[CV 1/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=  24.1s\n",
      "[CV 2/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=  24.4s\n",
      "[CV 3/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=  28.3s\n",
      "[CV 4/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=  25.8s\n",
      "[CV 5/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=  27.6s\n",
      "[CV 1/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=  27.6s\n",
      "[CV 2/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=  26.2s\n",
      "[CV 3/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=  26.1s\n",
      "[CV 4/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=  24.6s\n",
      "[CV 5/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=  25.2s\n",
      "[CV 1/5] END .................C=100, gamma=0.001, kernel=rbf; total time=  25.3s\n",
      "[CV 2/5] END .................C=100, gamma=0.001, kernel=rbf; total time=  24.3s\n",
      "[CV 3/5] END .................C=100, gamma=0.001, kernel=rbf; total time=  24.5s\n",
      "[CV 4/5] END .................C=100, gamma=0.001, kernel=rbf; total time=  24.3s\n",
      "[CV 5/5] END .................C=100, gamma=0.001, kernel=rbf; total time=  24.5s\n",
      "[CV 1/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=  23.7s\n",
      "[CV 2/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=  23.6s\n",
      "[CV 3/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=  23.7s\n",
      "[CV 4/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=  23.3s\n",
      "[CV 5/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=  22.7s\n",
      "[CV 1/5] END ....................C=1000, gamma=1, kernel=rbf; total time=  24.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....................C=1000, gamma=1, kernel=rbf; total time=  24.3s\n",
      "[CV 3/5] END ....................C=1000, gamma=1, kernel=rbf; total time=  24.1s\n",
      "[CV 4/5] END ....................C=1000, gamma=1, kernel=rbf; total time=  24.5s\n",
      "[CV 5/5] END ....................C=1000, gamma=1, kernel=rbf; total time=  24.3s\n",
      "[CV 1/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=  24.2s\n",
      "[CV 2/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=  24.2s\n",
      "[CV 3/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=  24.3s\n",
      "[CV 4/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=  24.3s\n",
      "[CV 5/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=  24.2s\n",
      "[CV 1/5] END .................C=1000, gamma=0.01, kernel=rbf; total time=  24.0s\n",
      "[CV 2/5] END .................C=1000, gamma=0.01, kernel=rbf; total time=  24.0s\n",
      "[CV 3/5] END .................C=1000, gamma=0.01, kernel=rbf; total time=  23.3s\n",
      "[CV 4/5] END .................C=1000, gamma=0.01, kernel=rbf; total time=  23.4s\n",
      "[CV 5/5] END .................C=1000, gamma=0.01, kernel=rbf; total time=  24.0s\n",
      "[CV 1/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=  25.2s\n",
      "[CV 2/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=  25.0s\n",
      "[CV 3/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=  23.4s\n",
      "[CV 4/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=  24.3s\n",
      "[CV 5/5] END ................C=1000, gamma=0.001, kernel=rbf; total time=  23.9s\n",
      "[CV 1/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=  23.5s\n",
      "[CV 2/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=  23.3s\n",
      "[CV 3/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=  23.1s\n",
      "[CV 4/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=  23.9s\n",
      "[CV 5/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=  23.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} \n",
    "grid_svm = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "grid_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "SVC(C=10, gamma=0.0001)\n"
     ]
    }
   ],
   "source": [
    "print(grid_svm.best_params_)\n",
    "print(grid_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  model takes 150.439 seconds\n",
      "Accuracy of SVM on test set: 0.519\n",
      "Predicting test data takes 12.722 seconds\n",
      "Classification error rate: 0.48074921956295524\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.05      0.09       484\n",
      "           1       0.51      1.00      0.67       477\n",
      "\n",
      "    accuracy                           0.52       961\n",
      "   macro avg       0.72      0.52      0.38       961\n",
      "weighted avg       0.72      0.52      0.38       961\n",
      "\n",
      "Confusion Matrix \n",
      " [[ 24 460]\n",
      " [  2 475]]\n",
      "AUC is: 0.5340\n"
     ]
    }
   ],
   "source": [
    "#Train SVM using best parameters\n",
    "svm_best = SVC(C=10,gamma=0.0001,kernel='rbf',probability=True) \n",
    "start_time=time.time()\n",
    "svm_best.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "print('Accuracy of SVM on test set: {:.3f}'.format(svm_best.score(X_test,y_test)))\n",
    "\n",
    "start = time.time()\n",
    "svm_pred = svm_best.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "svm_predprob = svm_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print('Classification error rate:', np.mean(np.array(y_test)!= svm_pred))\n",
    "print('Classification report \\n', classification_report(y_test, svm_pred))\n",
    "\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test, svm_pred))\n",
    "print('AUC is: {:.4f}'.format(roc_auc_score(y_test, svm_predprob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save trained SVM model\n",
    "pickle.dump(svm_best, open(\"../output/best_svm.p\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weighted SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.708\n"
     ]
    }
   ],
   "source": [
    "weighted_svm = SVC(gamma = 'scale', class_weight = 'balanced')\n",
    "\n",
    "#CV Weighted SVM \n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(weighted_svm, X, Y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "# summarize performance\n",
    "print('Mean ROC AUC: %.3f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight={0: 598.0, 1: 2402.0})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance = [{0:598.0, 1:2402.0},{0:1,1:100}, {0:1,1:10}, {0:1,1:1}, {0:10,1:1}, {0:100,1:1}]\n",
    "param_grid = dict(class_weight=balance)\n",
    "\n",
    "grid_weightedsvm = GridSearchCV(estimator=weighted_svm, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
    "grid_weightedsvm.fit(X,Y)\n",
    "grid_weightedsvm.best_params_\n",
    "grid_weightedsvm.best_estimator_\n",
    "grid_weightedsvm.best_params_\n",
    "grid_weightedsvm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.827703 using {'class_weight': {0: 598.0, 1: 2402.0}}\n",
      "0.827703 (0.030973) with: {'class_weight': {0: 598.0, 1: 2402.0}}\n",
      "0.792564 (0.035455) with: {'class_weight': {0: 1, 1: 100}}\n",
      "0.782922 (0.031263) with: {'class_weight': {0: 1, 1: 10}}\n",
      "0.798206 (0.034647) with: {'class_weight': {0: 1, 1: 1}}\n",
      "0.796063 (0.030676) with: {'class_weight': {0: 10, 1: 1}}\n",
      "0.796048 (0.030652) with: {'class_weight': {0: 100, 1: 1}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_weightedsvm.best_score_, grid_weightedsvm.best_params_))\n",
    "# report all configurations\n",
    "means = grid_weightedsvm.cv_results_['mean_test_score']\n",
    "stds = grid_weightedsvm.cv_results_['std_test_score']\n",
    "params = grid_weightedsvm.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  model takes 62.867 seconds\n",
      "Accuracy of weighted SVM on test set: 0.863\n",
      "[0 1 1 0 0]\n",
      "Predicting test data takes 4.626 seconds\n",
      "Classification error rate: 0.11446409989594172\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88       484\n",
      "           1       0.85      0.93      0.89       477\n",
      "\n",
      "    accuracy                           0.89       961\n",
      "   macro avg       0.89      0.89      0.89       961\n",
      "weighted avg       0.89      0.89      0.89       961\n",
      "\n",
      "Confusion Matrix \n",
      " [[408  76]\n",
      " [ 34 443]]\n",
      "AUC is: 0.9465\n"
     ]
    }
   ],
   "source": [
    "weighted_svm_best = SVC(gamma = 'scale', class_weight ={0: 598.0, 1: 2402.0},probability=True)\n",
    "start_time=time.time()\n",
    "weighted_svm_best.fit(X, Y)\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "print('Accuracy of weighted SVM on test set: {:.3f}'.format(weighted_svm_best.score(X,Y)))\n",
    "\n",
    "start = time.time()\n",
    "weighted_svm_pred = weighted_svm_best.predict(X_test)\n",
    "end = time.time()\n",
    "print(weighted_svm_pred[0:5,])\n",
    "\n",
    "weighted_svm_predprob = weighted_svm_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print('Classification error rate:', np.mean(np.array(y_test)!= weighted_svm_pred))\n",
    "print('Classification report \\n', classification_report(y_test, weighted_svm_pred))\n",
    "\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test, weighted_svm_pred))\n",
    "print('AUC is: {:.4f}'.format(roc_auc_score(y_test, weighted_svm_predprob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save trained weighted SVM model\n",
    "pickle.dump(weighted_svm_best, open(\"../output/best_weighted_svm.p\",'wb'))\n",
    "\n",
    "#Load weighted SVM model\n",
    "pickle.load(open(\"../output/best_weighted_svm.p\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.0001, probability=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load SVM balanced model\n",
    "pickle.load(open(\"../output/best_svm.p\",'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other models (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  model takes 0.073 seconds\n",
      "Predicting test data takes 0.018 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.53      0.65       479\n",
      "           1       0.24      0.59      0.34       121\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.54      0.56      0.49       600\n",
      "weighted avg       0.71      0.54      0.58       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = NearestCentroid()\n",
    "start_time=time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "NearestCentroid()\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "start = time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(y_test,pre))\n",
    "\n",
    "#Save trained knn model\n",
    "pickle.dump(weighted_svm_best, open(\"../output/best_weighted_svm.p\",'wb'))\n",
    "\n",
    "#Load weighted SVM model\n",
    "pickle.load(open(\"../output/best_weighted_svm.p\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score of a model with k = 3 is 0.776667\n",
      "the recall of a model with k = 3 is 0.223140\n",
      "the score of a model with k = 4 is 0.800000\n",
      "the recall of a model with k = 4 is 0.090909\n",
      "the score of a model with k = 5 is 0.786667\n",
      "the recall of a model with k = 5 is 0.148760\n",
      "the score of a model with k = 6 is 0.800000\n",
      "the recall of a model with k = 6 is 0.082645\n",
      "the score of a model with k = 7 is 0.790000\n",
      "the recall of a model with k = 7 is 0.115702\n",
      "the score of a model with k = 8 is 0.810000\n",
      "the recall of a model with k = 8 is 0.082645\n",
      "the score of a model with k = 9 is 0.803333\n",
      "the recall of a model with k = 9 is 0.132231\n",
      "the score of a model with k = 3 is 0.776667\n",
      "the recall of a model with k = 3 is 0.223140\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       479\n",
      "           1       0.40      0.22      0.29       121\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.61      0.57      0.58       600\n",
      "weighted avg       0.74      0.78      0.75       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis,KNeighborsClassifier)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "for k in range(3,10):\n",
    "    nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "    nca_pipe.fit(X_train, y_train)\n",
    "    pre=nca_pipe.predict(X_test)\n",
    "    # Pipeline(...)\n",
    "    print('the score of a model with k = %d is %f' % (k, nca_pipe.score(X_test, y_test)))\n",
    "    print('the recall of a model with k = %d is %f' % (k, recall_score(y_test, pre)))\n",
    "    \n",
    "    \n",
    "\n",
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis,KNeighborsClassifier)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "k=3\n",
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(X_train, y_train)\n",
    "# Pipeline(...)\n",
    "pre=nca_pipe.predict(X_test)\n",
    "# Pipeline(...)\n",
    "print('the score of a model with k = %d is %f' % (k, nca_pipe.score(X_test, y_test)))\n",
    "print('the recall of a model with k = %d is %f' % (k, recall_score(y_test, pre)))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pre=nca_pipe.predict(X_test)\n",
    "print(classification_report(y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  model takes 4.778 seconds\n",
      "Predicting test data takes 0.008 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.64      0.76       479\n",
      "           1       0.35      0.78      0.49       121\n",
      "\n",
      "    accuracy                           0.67       600\n",
      "   macro avg       0.64      0.71      0.62       600\n",
      "weighted avg       0.81      0.67      0.70       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "# SGD with penalty=l1\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"log\", penalty=\"l1\", max_iter=200, shuffle=True, class_weight='balanced')\n",
    "start_time=time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "start = time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  model takes 2.268 seconds\n",
      "Predicting test data takes 0.005 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06       479\n",
      "           1       0.21      1.00      0.34       121\n",
      "\n",
      "    accuracy                           0.23       600\n",
      "   macro avg       0.60      0.52      0.20       600\n",
      "weighted avg       0.84      0.23      0.12       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD with penalty=12\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss=\"log\", penalty=\"l2\", max_iter=200, shuffle=True, class_weight='balanced')\n",
    "start_time=time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "start = time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  model takes 0.296 seconds\n",
      "Predicting test data takes 0.005 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       479\n",
      "           1       0.00      0.00      0.00       121\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.40      0.50      0.44       600\n",
      "weighted avg       0.64      0.80      0.71       600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liqia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\liqia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\liqia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto',\n",
    "              beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
    "              epsilon=1e-08, hidden_layer_sizes=(5,2),\n",
    "              learning_rate='constant', learning_rate_init=0.001,\n",
    "              max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
    "              nesterovs_momentum=True, power_t=0.5, random_state=2,\n",
    "              shuffle=True, solver='lbfgs', tol=0.0001,\n",
    "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "start_time=time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "start = time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  model takes 2.673 seconds\n",
      "Predicting test data takes 0.008 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.77       479\n",
      "           1       0.31      0.53      0.39       121\n",
      "\n",
      "    accuracy                           0.67       600\n",
      "   macro avg       0.58      0.62      0.58       600\n",
      "weighted avg       0.75      0.67      0.70       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 30, min_samples_leaf=2, max_leaf_nodes=3, class_weight='balanced')\n",
    "start_time=time.time()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "start = time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  model takes 29.645 seconds\n",
      "Predicting test data takes 0.122 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89       479\n",
      "           1       0.76      0.11      0.19       121\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.79      0.55      0.54       600\n",
      "weighted avg       0.80      0.81      0.75       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest & Adaboost\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, class_weight='balanced')\n",
    "start_time=time.time()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "start = time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  model takes 318.494 seconds\n",
      "Predicting test data takes 645.113 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       479\n",
      "           1       0.53      0.42      0.47       121\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.69      0.66      0.67       600\n",
      "weighted avg       0.79      0.81      0.80       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=200)\n",
    "start_time=time.time()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "start_time=time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  model takes 202.349 seconds\n",
      "Predicting test data takes 848.637 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       479\n",
      "           1       0.49      0.32      0.39       121\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.67      0.62      0.63       600\n",
      "weighted avg       0.77      0.80      0.78       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "start_time=time.time()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "#scores = cross_val_score(clf, img_set, label, cv=5)\n",
    "#print('the 5-fold cross validation score for AdaBoost with 100 estimators is %f' % scores.mean())\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "start_time=time.time()\n",
    "pre=clf.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print(classification_report(y_test,pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
